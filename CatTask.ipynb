{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дан набор предложений, скопированных с Википедии. Каждое из них имеет \"кошачью тему\" в одном из трех смыслов:\n",
    "\n",
    "* кошки (животные)\n",
    "* UNIX-утилита cat для вывода содержимого файлов\n",
    "* версии операционной системы OS X, названные в честь семейства кошачьих\n",
    "\n",
    "Ваша задача — найти два предложения, которые ближе всего по смыслу к расположенному в самой первой строке. В качестве меры близости по смыслу мы будем использовать косинусное расстояние.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open('sentences.txt', 'rt') as f:\n",
    "    all_words = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "all_words = list(filter(lambda x: len(x), re.split('[^a-z]', all_words.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте список всех слов, встречающихся в предложениях. Сопоставьте каждому слову индекс от нуля до (d - 1), где d — число различных слов в предложениях. Для этого удобно воспользоваться структурой dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexed_words = {}\n",
    "index = 0\n",
    "import re\n",
    "for word in all_words:\n",
    "    if word not in indexed_words:\n",
    "        indexed_words[word] = index\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Создайте матрицу размера n * d, где n — число предложений. Заполните ее: элемент с индексом (i, j) в этой матрице должен быть равен количеству вхождений j-го слова в i-е предложение. У вас должна получиться матрица размера 22 * 254."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizeString(string):\n",
    "    return list(filter(lambda x: len(x), re.split('[^a-z]', string.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('sentences.txt', 'rt') as f:\n",
    "    all_sentences = f.readlines()\n",
    "    \n",
    "array = np.zeros((len(all_sentences), len(indexed_words.keys())))\n",
    "\n",
    "for i in range(len(all_sentences)):\n",
    "    all_sentences[i] = tokenizeString(all_sentences[i])\n",
    "    for word in all_sentences[i]:\n",
    "        array[i, indexed_words[word]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) до всех остальных с помощью функции scipy.spatial.distance.cosine. Какие номера у двух предложений, ближайших к нему по этому расстоянию (строки нумеруются с нуля)? Эти два числа и будут ответами на задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => 0.0\n",
      "1 => 0.9527544408738466\n",
      "2 => 0.8644738145642124\n",
      "3 => 0.8951715163278082\n",
      "4 => 0.7770887149698589\n",
      "5 => 0.9402385695332803\n",
      "6 => 0.7327387580875756\n",
      "7 => 0.9258750683338899\n",
      "8 => 0.884272487528431\n",
      "9 => 0.9055088817476932\n",
      "10 => 0.8328165362273942\n",
      "11 => 0.8804771390665607\n",
      "12 => 0.8396432548525454\n",
      "13 => 0.8703592552895671\n",
      "14 => 0.8740118423302576\n",
      "15 => 0.9442721787424647\n",
      "16 => 0.8406361854220809\n",
      "17 => 0.956644501523794\n",
      "18 => 0.9442721787424647\n",
      "19 => 0.8885443574849294\n",
      "20 => 0.8427572744917122\n",
      "21 => 0.8250364469440586\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(all_sentences)):\n",
    "    print(\"{0} => {1}\".format(i, cosine(array[0], array[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
